{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mish841/RAISE-26-Data-Science-AI-Competition-Submission/blob/mishal-phase2-progress/data_science_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries and load dataset of 10500 AI related articles."
      ],
      "metadata": {
        "id": "q4jymvungdeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saMVZDlDNgsJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "DATA_PATH = \"dataset_A_news_full_10500.csv\"\n",
        "# df = pd.read_csv(\"dataset_A_news_full_10500.csv\")\n",
        "\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks for missing values and converts the date column to datetime format for temporal analysis"
      ],
      "metadata": {
        "id": "YP6BzvkAgiej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df.isna().sum().sort_values(ascending=False).head(20)\n",
        "# After loading the data\n",
        "df['date'] = pd.to_datetime(df['date'])"
      ],
      "metadata": {
        "id": "tf0e3Ag5vUQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Frequency: Analyzes how frequently different content categories appear. Each article can have multiples categories seperated by semicolons."
      ],
      "metadata": {
        "id": "OsLdhE0EUsaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes = []\n",
        "for classes_str in df['classes_str']:\n",
        "    classes = [c.strip() for c in str(classes_str).split(';')]\n",
        "    all_classes.extend(classes)\n",
        "\n",
        "# Count occurrences\n",
        "class_counts = Counter(all_classes)\n",
        "\n",
        "# Convert to DataFrame\n",
        "class_df = pd.DataFrame(\n",
        "    class_counts.items(),\n",
        "    columns=['class', 'count']\n",
        ").sort_values('count', ascending=False).reset_index(drop=True)\n",
        "\n",
        "class_df.head(15)"
      ],
      "metadata": {
        "id": "maXSJfVfKYAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Domain article frequency: Creates binary indicator columns and mark which domain category is present in each article."
      ],
      "metadata": {
        "id": "VGPds3pwUq9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boolean columns for ALL 12 categories using EXACT names\n",
        "df['is_sentiment'] = df['classes_str'].apply(lambda x: 'Sentiment (Positive / Negative Feelings)' in x)\n",
        "df['is_emotion'] = df['classes_str'].apply(lambda x: 'Emotion, Motivation & Well-being' in x)\n",
        "df['is_human_roles'] = df['classes_str'].apply(lambda x: 'Human Roles' in x)\n",
        "df['is_behavior'] = df['classes_str'].apply(lambda x: 'Routine, Lifestyle & Behavior' in x)\n",
        "df['is_cognitive'] = df['classes_str'].apply(lambda x: 'Cognitive & Decision-Making' in x)\n",
        "df['is_creativity'] = df['classes_str'].apply(lambda x: 'Creativity, Expression & Identity' in x)\n",
        "df['is_relationships'] = df['classes_str'].apply(lambda x: 'Social Interaction & Relationships' in x)\n",
        "df['is_work'] = df['classes_str'].apply(lambda x: 'Work, Jobs & Economy' in x)\n",
        "df['is_education'] = df['classes_str'].apply(lambda x: 'Learning, Knowledge & Education' in x)\n",
        "df['is_health'] = df['classes_str'].apply(lambda x: 'Health, Safety & Risk' in x)\n",
        "df['is_society'] = df['classes_str'].apply(lambda x: 'Society, Ethics & Culture' in x)\n",
        "df['is_technology'] = df['classes_str'].apply(lambda x: 'Technology & Interaction' in x)\n",
        "\n"
      ],
      "metadata": {
        "id": "sT2L5pbNTwsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "domain_map = {\n",
        "    'Sentiment (Positive / Negative Feelings)': 'is_sentiment',\n",
        "    'Emotion, Motivation & Well-being': 'is_emotion',\n",
        "    'Human Roles': 'is_human_roles',\n",
        "    'Routine, Lifestyle & Behavior': 'is_behavior',\n",
        "    'Cognitive & Decision-Making': 'is_cognitive',\n",
        "    'Creativity, Expression & Identity': 'is_creativity',\n",
        "    'Social Interaction & Relationships': 'is_relationships',\n",
        "    'Work, Jobs & Economy': 'is_work',\n",
        "    'Learning, Knowledge & Education': 'is_education',\n",
        "    'Health, Safety & Risk': 'is_health',\n",
        "    'Society, Ethics & Culture': 'is_society',\n",
        "    'Technology & Interaction': 'is_technology'\n",
        "}\n",
        "\n",
        "print(\"\\nKey Research Domain Counts:\")\n",
        "\n",
        "for label, col in domain_map.items():\n",
        "    count = df[col].sum()\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"{label:40} {count:5} articles ({percentage:5.1f}%)\")\n"
      ],
      "metadata": {
        "id": "7RSBnChomDS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Seed Words: Creates emotion dictionaries by starting with seed words and expanding them using synonyms from WordNet. This creates comprehensive lists of emotion related words to search for in headlines."
      ],
      "metadata": {
        "id": "Jumz6iISVaG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_emotions = {\n",
        "    'fear': ['fear', 'threat', 'danger'],\n",
        "    'anxiety': ['anxiety', 'worry', 'uncertainty'],\n",
        "    'optimism': ['hope', 'opportunity', 'promise'],\n",
        "    'trust': ['trust', 'confidence', 'reliability']\n",
        "}\n",
        "\n",
        "def expand_emotion_words(seed_list):\n",
        "    words = set(seed_list)\n",
        "    for seed in seed_list:\n",
        "        for syn in wn.synsets(seed):\n",
        "            for lemma in syn.lemmas():\n",
        "                words.add(lemma.name().lower().replace('_', ' '))\n",
        "    return words\n",
        "\n",
        "emotion_buckets = {\n",
        "    emotion: expand_emotion_words(seeds)\n",
        "    for emotion, seeds in seed_emotions.items()\n",
        "}\n"
      ],
      "metadata": {
        "id": "aZ6Cukq5Vc8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function counts how many emotion-related words appear in each headline, creating numerical scores for fear, anxiety, optimism, and trust."
      ],
      "metadata": {
        "id": "i7_cUGS0cPVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_emotion_words(text, word_list):\n",
        "    if not isinstance(text, str):\n",
        "        return 0\n",
        "    text = text.lower()\n",
        "    return sum(word in text for word in word_list)\n",
        "\n",
        "emotion = pd.DataFrame()\n",
        "emotion['title'] = df['title']\n",
        "emotion['fear_score'] = df['title'].apply(lambda x: count_emotion_words(x, emotion_buckets['fear']))\n",
        "emotion['anxiety_score'] = df['title'].apply(lambda x: count_emotion_words(x, emotion_buckets['anxiety']))\n",
        "emotion['optimism_score'] = df['title'].apply(lambda x: count_emotion_words(x, emotion_buckets['optimism']))\n",
        "emotion['trust_score'] = df['title'].apply(lambda x: count_emotion_words(x, emotion_buckets['trust']))\n",
        "\n",
        "emotion.head(15)"
      ],
      "metadata": {
        "id": "N1WR169McdFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provides statistical summary of emotion scores across all articles."
      ],
      "metadata": {
        "id": "FA0VYQpXyaM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion[['fear_score','anxiety_score','optimism_score','trust_score']].describe()\n"
      ],
      "metadata": {
        "id": "vN4eX-9dwX2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzes how emotional framing in AI news headlines changes over months throughout 2025. Creates vizualization showing temporal emotion trends."
      ],
      "metadata": {
        "id": "U3xm8s4ehO5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion['year'] = df['year']\n",
        "emotion['month'] = df['month']\n",
        "\n",
        "#Aggregate by month since the year is 2025 for all headlines\n",
        "emotion_by_month = emotion.groupby('month')[\n",
        "    ['fear_score','anxiety_score','optimism_score','trust_score']\n",
        "].mean()\n",
        "\n",
        "# Order months chronologically for plotting\n",
        "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "emotion_by_month = emotion_by_month.reindex(month_order)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot trends\n",
        "emotion_by_month.plot(\n",
        "    figsize=(12,7),\n",
        "    title='Emotional Framing of AI Over Time by Month',\n",
        "    marker='o' # Add markers for better visibility of data points\n",
        ")\n",
        "plt.xlabel('Month in 2025')\n",
        "plt.ylabel('Average Emotion Score')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "emotion_by_month"
      ],
      "metadata": {
        "id": "0_VJw4P4hPTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Fear (blue) is the dominant\n",
        "emotion, consistently around 0.10 - 0.12.\n",
        "Peaks in August (0.117) - highest fear period\n",
        "*   Optimism (green) is the second highest, ranging from 0.06 - 0.07.\n",
        "Peaks in July (0.068)\n",
        "\n",
        "*  Anxiety (orange) stays relatively stable approx 0.05.\n",
        "Slight increase in August\n",
        "*  Trust (red) is the lowest emotion, around 0.04 - 0.05\n",
        "\n",
        "\n",
        "Interpretation: AI news coverage is predominantly fear-focused rather than optimistic, with trust being notably low throughout the summer.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-CpL_QAtGjAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization and Setup\n"
      ],
      "metadata": {
        "id": "hL4unyQ_6x7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "OUTPUT_DIR = 'analysis_outputs'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "    print(f\"✓ Created output directory: {OUTPUT_DIR}\")\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TF-IDF VECTORIZATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=1000,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),  # Include bigrams\n",
        "    min_df=5,  # Ignore rare terms\n",
        "    max_df=0.8  # Ignore common terms\n",
        ")\n",
        "\n",
        "X_tfidf = tfidf.fit_transform(emotion['title'])  # Using your emotion DataFrame\n",
        "\n",
        "print(f\"TF-IDF matrix shape: {X_tfidf.shape}\")\n",
        "print(f\"Total features extracted: {len(tfidf.get_feature_names_out())}\")\n",
        "print(f\"\\n✓ TF-IDF vectorization complete!\")\n"
      ],
      "metadata": {
        "id": "H7d_UPf06ztw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic Modeling with KMeans\n",
        "\n"
      ],
      "metadata": {
        "id": "bHfXEgio5i6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "inertias = []\n",
        "K_range = range(3, 12)\n",
        "\n",
        "print(\"\\nCalculating optimal number of clusters...\")\n",
        "for k in K_range:\n",
        "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans_temp.fit(X_tfidf)\n",
        "    inertias.append(kmeans_temp.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K_range, inertias, 'bo-')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/elbow_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(f\"✓ Saved: {OUTPUT_DIR}/elbow_curve.png\")\n",
        "\n",
        "# Use 6 clusters (you can adjust based on elbow curve)\n",
        "n_clusters = 6\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "df['topic_cluster'] = kmeans.fit_predict(X_tfidf)\n",
        "\n",
        "print(f\"\\nUsing {n_clusters} clusters\")\n",
        "print(f\"\\nTopic distribution:\")\n",
        "print(df['topic_cluster'].value_counts().sort_index())"
      ],
      "metadata": {
        "id": "aVbgJA0K5oQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Top Keywords per Topic: Identifies the 10 most characteristic words for each topic cluster, helping understand what each cluster is about.\n"
      ],
      "metadata": {
        "id": "RoZgsurl7aUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TOPIC CHARACTERIZATION - TOP KEYWORDS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "\n",
        "topic_keywords = {}\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    top_terms = [feature_names[ind] for ind in order_centroids[i, :10]]\n",
        "    topic_keywords[i] = top_terms\n",
        "    print(f\"\\nTopic {i}:\")\n",
        "    print(f\"  Keywords: {', '.join(top_terms)}\")\n",
        "\n",
        "    # Get sample headlines from this topic\n",
        "    topic_data = df[df['topic_cluster'] == i]\n",
        "    print(f\"  Size: {len(topic_data)} articles ({len(topic_data)/len(df)*100:.1f}%)\")\n",
        "    print(f\"  Sample headlines:\")\n",
        "    for idx, title in enumerate(topic_data.sample(min(2, len(topic_data)))['title'].values, 1):\n",
        "        print(f\"    {idx}. {title}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Jr0Vg3JL7bAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion Profiles by Topic:  Creates a heatmap showing which emotions are most prevalent in each topic cluster, revealing the emotional character of different AI news topics."
      ],
      "metadata": {
        "id": "i_IHlt2s7fPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"INTEGRATED ANALYSIS: EMOTION PROFILES BY TOPIC\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Merge topic clusters into your emotion DataFrame\n",
        "emotion['topic_cluster'] = df['topic_cluster']\n",
        "\n",
        "# Calculate emotion scores by topic\n",
        "emotion_by_topic = emotion.groupby('topic_cluster')[\n",
        "    ['fear_score', 'anxiety_score', 'optimism_score', 'trust_score']\n",
        "].mean()\n",
        "\n",
        "print(\"\\nAverage emotion scores by topic:\")\n",
        "print(emotion_by_topic.round(3))\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Heatmap of emotions by topic\n",
        "ax = axes[0, 0]\n",
        "sns.heatmap(emotion_by_topic, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax,\n",
        "            cbar_kws={'label': 'Average Score'})\n",
        "ax.set_title('Emotion Profiles by Topic Cluster', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Emotion Type')\n",
        "ax.set_ylabel('Topic Cluster')\n",
        "\n",
        "# Plot 2: Emotion balance by topic\n",
        "ax = axes[0, 1]\n",
        "emotion['emotion_balance'] = (emotion['optimism_score'] + emotion['trust_score']) - \\\n",
        "                              (emotion['fear_score'] + emotion['anxiety_score'])\n",
        "emotion_balance_by_topic = emotion.groupby('topic_cluster')['emotion_balance'].mean().sort_values()\n",
        "colors = ['red' if x < 0 else 'green' for x in emotion_balance_by_topic.values]\n",
        "emotion_balance_by_topic.plot(kind='barh', ax=ax, color=colors)\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.set_title('Emotion Balance by Topic (Positive - Negative)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Balance Score')\n",
        "\n",
        "# Plot 3: Topic sizes\n",
        "ax = axes[1, 0]\n",
        "topic_sizes = emotion['topic_cluster'].value_counts().sort_index()\n",
        "bars = ax.bar(topic_sizes.index, topic_sizes.values, color='steelblue', alpha=0.6)\n",
        "ax.set_xlabel('Topic Cluster')\n",
        "ax.set_ylabel('Number of Articles')\n",
        "ax.set_title('Topic Distribution', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(range(n_clusters))\n",
        "\n",
        "# Plot 4: Scatter - Positive vs Negative by topic\n",
        "ax = axes[1, 1]\n",
        "for topic in range(n_clusters):\n",
        "    topic_data = emotion_by_topic.loc[topic]\n",
        "    neg_score = topic_data['fear_score'] + topic_data['anxiety_score']\n",
        "    pos_score = topic_data['optimism_score'] + topic_data['trust_score']\n",
        "    ax.scatter(neg_score, pos_score, s=200, alpha=0.6, label=f'Topic {topic}')\n",
        "\n",
        "max_val = max(emotion_by_topic.values.max(), 1)\n",
        "ax.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, label='Balance Line')\n",
        "ax.set_xlabel('Negative Emotion Score (Fear + Anxiety)')\n",
        "ax.set_ylabel('Positive Emotion Score (Optimism + Trust)')\n",
        "ax.set_title('Positive vs Negative Emotions by Topic', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=8)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/emotion_topic_profiles.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Saved: {OUTPUT_DIR}/emotion_topic_profiles.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VrvdgUrA7hWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Domain Distribution by Topic: Shows which content domains (work, education, health, etc.) are most associated with each topic cluster."
      ],
      "metadata": {
        "id": "7Uach7WB8Bjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top-Left: Emotion Heatmap**\n",
        "\n",
        "* Topic 2 & 3 have the highest fear (dark green = 0.12)\n",
        "* Topic 5 has the lowest anxiety (dark red = 0.02) and lowest fear (0.04)\n",
        "* Topic 1 has relatively high optimism (0.10) and low trust (0.03)\n",
        "* Most topics show fear > optimism, except Topic 5\n",
        "\n",
        "\n",
        "**Top-Right: Emotion Balance**\n",
        "\n",
        "* ALL topics except Topic 5 have negative emotion balance (red bars)\n",
        "* This means negative emotions (fear + anxiety) outweigh positive ones (optimism + trust)\n",
        "* Topic 5 is the ONLY positive topic (green bar = +0.02)\n",
        "\n",
        "**Bottom-Left: Topic Distribution**\n",
        "\n",
        "* Topic 3 dominates with ~7,600 articles (72% of dataset!)\n",
        "* Topics 0, 1, 2, 4, 5 are much smaller (200-1,700 articles each)\n",
        "* This is very imbalanced - one topic overwhelms the dataset\n",
        "\n",
        "**Bottom-Right: Positive vs Negative Scatter**\n",
        "\n",
        "* All topics cluster in the lower-left quadrant = low positive, low-to-moderate negative\n",
        "* Topic 5 (purple) is closest to the balance line but still slightly below\n",
        "* Most topics have more negative than positive emotional content\n",
        "\n",
        "Interpretation: The dataset is dominated by one massive topic (Topic 3) about work/jobs, and most topics lean negative emotionally."
      ],
      "metadata": {
        "id": "jewjFX5zJCYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOMAIN DISTRIBUTION BY TOPIC"
      ],
      "metadata": {
        "id": "quYpdGSNN7aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DOMAIN DISTRIBUTION BY TOPIC\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Use your existing domain columns\n",
        "domain_cols = ['is_sentiment', 'is_emotion', 'is_human_roles', 'is_behavior',\n",
        "               'is_cognitive', 'is_creativity', 'is_relationships', 'is_work',\n",
        "               'is_education', 'is_health', 'is_society', 'is_technology']\n",
        "\n",
        "domain_by_topic = df.groupby('topic_cluster')[domain_cols].mean()\n",
        "\n",
        "print(\"\\nDomain prevalence by topic (proportion of articles):\")\n",
        "print(domain_by_topic.round(3))\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(14, 8))\n",
        "domain_by_topic.T.plot(kind='bar', width=0.8)\n",
        "plt.xlabel('Domain Category', fontsize=12)\n",
        "plt.ylabel('Proportion of Articles', fontsize=12)\n",
        "plt.title('Domain Distribution Across Topics', fontsize=14, fontweight='bold')\n",
        "plt.legend(title='Topic Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/domain_topic_distribution.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Saved: {OUTPUT_DIR}/domain_topic_distribution.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NxiVrW5x8DzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Topic 5 (brown) is 100% education-focused\n",
        "* Topic 4 (light purple) is 100% technology-focused\n",
        "* Topic 3 (dark purple) strongly associates with work/jobs domain (~0.3 proportion)\n",
        "* All other topics have mixed domain associations\n",
        "* Most topics show presence across sentiment, emotion, behavior, relationships, and society domains\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "* Topics 4 & 5 are pure/specialized (single-domain)\n",
        "* Topics 0-3 are mixed/general (multi-domain)\n",
        "* Work/economy and education are strong differentiators"
      ],
      "metadata": {
        "id": "Yf0jUXW6OYkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic-Specific Temporal Analysis: Creates separate time-series plots for each topic, showing how emotions evolve differently across different AI news themes over the months."
      ],
      "metadata": {
        "id": "3Eomz3Fm8QEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprehensive Topic Summary: Generates a complete summary table for each topic including article count, percentage, top keywords, average emotions, emotion balance (negative vs positive), and dominant content domain."
      ],
      "metadata": {
        "id": "LEKkUbsC8bU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TOPIC-SPECIFIC TEMPORAL ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
        "               'July', 'August', 'September', 'October', 'November', 'December']\n",
        "\n",
        "# Create figure with subplots for each topic\n",
        "fig, axes = plt.subplots(3, 2, figsize=(18, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for topic_id in range(n_clusters):\n",
        "    ax = axes[topic_id]\n",
        "\n",
        "    # Filter emotion data for this topic\n",
        "    topic_emotion = emotion[emotion['topic_cluster'] == topic_id]\n",
        "\n",
        "    # Get emotion trends by month\n",
        "    topic_emotion_month = topic_emotion.groupby('month')[\n",
        "        ['fear_score', 'anxiety_score', 'optimism_score', 'trust_score']\n",
        "    ].mean().reindex(month_order)\n",
        "\n",
        "    # Plot\n",
        "    topic_emotion_month.plot(ax=ax, marker='o', linewidth=2)\n",
        "\n",
        "    # Add title with keywords\n",
        "    keywords_str = ', '.join(topic_keywords[topic_id][:5])\n",
        "    ax.set_title(f'Topic {topic_id}: {keywords_str}\\n(n={len(topic_emotion)} articles)',\n",
        "                 fontsize=10, fontweight='bold')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Avg Emotion Score')\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/topic_specific_temporal.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Saved: {OUTPUT_DIR}/topic_specific_temporal.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Wg1htdKv8Qr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic 0: \"new, new ai, new study, study, tool\" (Research/Innovation)\n",
        "\n",
        "* Fear increases dramatically in August\n",
        "* Optimism peaks in July, then declines\n",
        "* Trust gradually increases over time\n",
        "* Pattern: Growing concern about new AI developments\n",
        "\n",
        "Topic 1: \"artificial intelligence, prediction\" (General AI)\n",
        "\n",
        "* Optimism highest in July, then drops sharply\n",
        "* Fear stays consistent ~0.10\n",
        "* Trust drops significantly by September\n",
        "Pattern: Declining optimism about AI's promises\n",
        "\n",
        "Topic 2: \"using, using ai, guide using, complete guide\" (AI Usage/Tutorials)\n",
        "\n",
        "* Fear skyrockets starting in July (0.00 → 0.13!)\n",
        "* All emotions increase dramatically\n",
        "* Pattern: Growing concerns about AI usage/implementation\n",
        "\n",
        "Topic 3: \"work, job, innovation, digital\" (Work/Economy) - 72% of articles!\n",
        "\n",
        "* Consistently high fear (~0.12) throughout\n",
        "* Low optimism (~0.06)\n",
        "* Stable over time\n",
        "* Pattern: Persistent job displacement fears\n",
        "\n",
        "Topic 4: \"adoption, ai adoption, report, government\" (Policy/Regulation)\n",
        "\n",
        "* Fear drops in July, then surges back\n",
        "* Volatile emotions, especially anxiety in August\n",
        "* Pattern: Uncertainty about AI governance\n",
        "\n",
        "Topic 5: \"education, ai education, higher education, schools\" (Education)\n",
        "\n",
        "* Complete reversal! Fear drops, optimism/trust surge in September\n",
        "* Only topic with positive trend\n",
        "* Pattern: Growing optimism about AI in education"
      ],
      "metadata": {
        "id": "dZNL3WH8POAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPREHENSIVE TOPIC SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "domain_map = {\n",
        "    'is_sentiment': 'Sentiment (Positive / Negative Feelings)',\n",
        "    'is_emotion': 'Emotion, Motivation & Well-being',\n",
        "    'is_human_roles': 'Human Roles',\n",
        "    'is_behavior': 'Routine, Lifestyle & Behavior',\n",
        "    'is_cognitive': 'Cognitive & Decision-Making',\n",
        "    'is_creativity': 'Creativity, Expression & Identity',\n",
        "    'is_relationships': 'Social Interaction & Relationships',\n",
        "    'is_work': 'Work, Jobs & Economy',\n",
        "    'is_education': 'Learning, Knowledge & Education',\n",
        "    'is_health': 'Health, Safety & Risk',\n",
        "    'is_society': 'Society, Ethics & Culture',\n",
        "    'is_technology': 'Technology & Interaction'\n",
        "}\n",
        "\n",
        "for topic_id in range(n_clusters):\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"TOPIC {topic_id}\")\n",
        "    print(f\"{'=' * 80}\")\n",
        "\n",
        "    topic_data = df[df['topic_cluster'] == topic_id]\n",
        "    topic_emotion = emotion[emotion['topic_cluster'] == topic_id]\n",
        "\n",
        "    # Basic stats\n",
        "    print(f\"\\nSIZE: {len(topic_data)} articles ({len(topic_data)/len(df)*100:.1f}%)\")\n",
        "\n",
        "    # Keywords\n",
        "    print(f\"\\n TOP KEYWORDS:\")\n",
        "    print(f\"   {', '.join(topic_keywords[topic_id][:10])}\")\n",
        "\n",
        "    # Emotion profile\n",
        "    print(f\"\\n EMOTION PROFILE:\")\n",
        "    emotions = topic_emotion[['fear_score', 'anxiety_score', 'optimism_score', 'trust_score']].mean()\n",
        "    for emotion_name, score in emotions.items():\n",
        "        print(f\"   {emotion_name:20} {score:.3f}\")\n",
        "\n",
        "    balance = topic_emotion['emotion_balance'].mean()\n",
        "    sentiment = \"POSITIVE ✓\" if balance > 0 else \"NEGATIVE ✗\"\n",
        "    print(f\"   Balance:             {balance:.3f} ({sentiment})\")\n",
        "\n",
        "    # Top domains\n",
        "    print(f\"\\n  TOP DOMAINS:\")\n",
        "    domain_scores = topic_data[domain_cols].mean().sort_values(ascending=False).head(3)\n",
        "    for domain, score in domain_scores.items():\n",
        "        domain_name = domain_map[domain]\n",
        "        print(f\"   {domain_name:45} {score:.3f}\")\n",
        "\n",
        "    # Sample headlines\n",
        "    print(f\"\\nSAMPLE HEADLINES:\")\n",
        "    samples = topic_data.sample(min(3, len(topic_data)))['title'].values\n",
        "    for i, headline in enumerate(samples, 1):\n",
        "        print(f\"   {i}. {headline}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UtbnJCAp8csD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Results Optional I think...\n"
      ],
      "metadata": {
        "id": "ozEPY4Rm8pqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPORTING RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Add topic cluster to main dataframe if not already there\n",
        "if 'topic_cluster' not in df.columns:\n",
        "    df['topic_cluster'] = emotion['topic_cluster']\n",
        "\n",
        "# Save enhanced dataframe\n",
        "output_path = f'{OUTPUT_DIR}/ai_news_analysis_with_topics.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"\\n✓ Enhanced dataset saved to: {output_path}\")\n",
        "\n",
        "# Create topic summary table\n",
        "summary_data = []\n",
        "for topic_id in range(n_clusters):\n",
        "    topic_data = df[df['topic_cluster'] == topic_id]\n",
        "    topic_emotion = emotion[emotion['topic_cluster'] == topic_id]\n",
        "\n",
        "    summary_data.append({\n",
        "        'topic_id': topic_id,\n",
        "        'n_articles': len(topic_data),\n",
        "        'percentage': len(topic_data) / len(df) * 100,\n",
        "        'top_keywords': ', '.join(topic_keywords[topic_id][:5]),\n",
        "        'avg_fear': topic_emotion['fear_score'].mean(),\n",
        "        'avg_anxiety': topic_emotion['anxiety_score'].mean(),\n",
        "        'avg_optimism': topic_emotion['optimism_score'].mean(),\n",
        "        'avg_trust': topic_emotion['trust_score'].mean(),\n",
        "        'emotion_balance': topic_emotion['emotion_balance'].mean(),\n",
        "        'top_domain': domain_by_topic.loc[topic_id].idxmax(),\n",
        "        'top_domain_score': domain_by_topic.loc[topic_id].max()\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_path = f'{OUTPUT_DIR}/topic_summary.csv'\n",
        "summary_df.to_csv(summary_path, index=False)\n",
        "print(f\"✓ Topic summary saved to: {summary_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"✅ ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nAll outputs in: {OUTPUT_DIR}/\")\n",
        "print(f\"\\nFiles created:\")\n",
        "print(f\"  1. elbow_curve.png\")\n",
        "print(f\"  2. emotion_topic_profiles.png\")\n",
        "print(f\"  3. domain_topic_distribution.png\")\n",
        "print(f\"  4. topic_specific_temporal.png\")\n",
        "print(f\"  5. ai_news_analysis_with_topics.csv\")\n",
        "print(f\"  6. topic_summary.csv\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TOPIC SUMMARY TABLE\")\n",
        "print(\"=\" * 80)\n",
        "display(summary_df)\n"
      ],
      "metadata": {
        "id": "Clv7OvNA8qZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agentic Reasoning Workflow (Dataset A & C)\n",
        "Given structured evidence from media coverage, synthesize how AI's impact on human behavior is framed by AI systems themselves:\n",
        "\n",
        "Step 1: Build Evidence Pack\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6hyMzIlYSE4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Monthly time key (sortable)\n",
        "df['month_date'] = df['date'].dt.to_period('M').dt.to_timestamp()\n",
        "\n",
        "# 2) Ensure emotion has the same key (only if emotion aligns row-wise with df)\n",
        "emotion = emotion.copy()\n",
        "emotion['month_date'] = df['month_date']\n",
        "\n",
        "# 3) Core time evidence\n",
        "emotion_by_month_date = (\n",
        "    emotion.groupby('month_date')[['fear_score','anxiety_score','optimism_score','trust_score']]\n",
        "          .mean()\n",
        "          .sort_index()\n",
        ")\n",
        "\n",
        "net_by_month = (\n",
        "    emotion_by_month_date['optimism_score'] + emotion_by_month_date['trust_score']\n",
        "    - emotion_by_month_date['fear_score'] - emotion_by_month_date['anxiety_score']\n",
        ")\n",
        "\n",
        "topic_share_by_month = (\n",
        "    emotion.groupby(['month_date','topic_cluster'])\n",
        "          .size()\n",
        "          .unstack(fill_value=0)\n",
        "          .pipe(lambda x: x.div(x.sum(axis=1), axis=0))\n",
        "          .sort_index()\n",
        ")\n",
        "\n",
        "# emotion_by_topic_month_date_df is already a DataFrame with MultiIndex\n",
        "emotion_by_topic_month_date_df = (\n",
        "    emotion.groupby(['topic_cluster','month_date'])[['fear_score','anxiety_score','optimism_score','trust_score']]\n",
        "          .mean()\n",
        "          .sort_index()\n",
        ")\n",
        "\n",
        "\n",
        "emotion['net_emotion'] = (\n",
        "    emotion['optimism_score'] + emotion['trust_score']\n",
        "    - emotion['fear_score'] - emotion['anxiety_score']\n",
        ")\n",
        "\n",
        "fear_examples = df.loc[emotion['net_emotion'].nsmallest(6).index, 'title'].tolist()\n",
        "optimism_examples = df.loc[emotion['net_emotion'].nlargest(6).index, 'title'].tolist()\n",
        "\n",
        "# --- Prepare DataFrames/Series for JSON serialization by converting Timestamp indices/columns to strings ---\n",
        "\n",
        "# Convert DataFrame/Series indices (Timestamps) to strings where they become dict keys\n",
        "emotion_by_month_date_json_ready = emotion_by_month_date.round(4).copy()\n",
        "emotion_by_month_date_json_ready.index = emotion_by_month_date_json_ready.index.astype(str)\n",
        "\n",
        "net_by_month_json_ready = net_by_month.round(4).copy()\n",
        "net_by_month_json_ready.index = net_by_month_json_ready.index.astype(str)\n",
        "\n",
        "topic_share_by_month_json_ready = topic_share_by_month.round(4).copy()\n",
        "topic_share_by_month_json_ready.index = topic_share_by_month_json_ready.index.astype(str)\n",
        "\n",
        "# For emotion_by_topic_month_date_df (MultiIndex DataFrame), reset index and convert month_date column to string\n",
        "emotion_by_topic_month_date_json_ready = emotion_by_topic_month_date_df.round(4).reset_index()\n",
        "emotion_by_topic_month_date_json_ready['month_date'] = emotion_by_topic_month_date_json_ready['month_date'].astype(str)\n",
        "\n",
        "\n",
        "evidence_pack = {\n",
        "    \"topic_summary_table\": summary_df.to_dict(orient=\"records\"),\n",
        "    \"emotion_by_topic\": emotion_by_topic.round(4).to_dict(),\n",
        "    \"emotion_balance_by_topic\": emotion_balance_by_topic.round(4).to_dict(),\n",
        "    \"topic_sizes\": topic_sizes.to_dict(),\n",
        "    \"topic_keywords\": topic_keywords,\n",
        "    \"domain_by_topic\": domain_by_topic.round(4).to_dict(),\n",
        "    \"emotion_by_topic_month_date\" : emotion_by_topic_month_date_json_ready.to_dict(orient=\"records\"), # Use the json_ready version\n",
        "    \"emotion_by_month_date\": emotion_by_month_date_json_ready.to_dict(), # Use the json_ready version\n",
        "    \"net_by_month\": net_by_month_json_ready.to_dict(), # Use the json_ready version\n",
        "    \"fear_examples\": fear_examples,\n",
        "    \"optimism_examples\" : optimism_examples,\n",
        "    \"topic_share_by_month\": topic_share_by_month_json_ready.to_dict() # Use the json_ready version\n",
        "}\n",
        "\n",
        "#run the evidence pack build\n",
        "evidence_pack.keys()\n",
        "\n"
      ],
      "metadata": {
        "id": "SQ9Ux6BmSZ8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Open-Weights Model - Phi-3.5-mini-instruct"
      ],
      "metadata": {
        "id": "J7QpxijPXeuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"microsoft/phi-3.5-mini-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "gen_config = {\n",
        "    \"max_new_tokens\": 220,\n",
        "    \"temperature\": 0.2,\n",
        "    \"top_p\": 0.9,\n",
        "    \"do_sample\": False\n",
        "}"
      ],
      "metadata": {
        "id": "LxPo6PvEXeaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Helper Functions for prompting + generation + logging"
      ],
      "metadata": {
        "id": "P5fgjB76acFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, time\n",
        "import torch\n",
        "\n",
        "RUN_ID = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "PROMPT_LOG_PATH = f\"analysis_outputs/agent_prompt_log_{RUN_ID}.jsonl\"\n",
        "AGENT_OUTPUT_PATH = f\"analysis_outputs/agent_outputs_{RUN_ID}.json\"\n",
        "\n",
        "def safe_json_dumps(obj, max_chars=12000):\n",
        "    \"\"\"\n",
        "    JSON dump but truncate if massive, so prompts stay small.\n",
        "    \"\"\"\n",
        "    s = json.dumps(obj, indent=2, default=str)\n",
        "    if len(s) > max_chars:\n",
        "        return s[:max_chars] + \"\\n...[TRUNCATED]...\"\n",
        "    return s\n",
        "\n",
        "def phi_generate(prompt: str, gen_config: dict):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=gen_config.get(\"max_new_tokens\", 400),\n",
        "            temperature=gen_config.get(\"temperature\", 0.2),\n",
        "            top_p=gen_config.get(\"top_p\", 0.9),\n",
        "            do_sample=gen_config.get(\"do_sample\", False),\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "    # Return only the assistant continuation if possible:\n",
        "    # Phi often echoes prompt; easiest robust approach: remove prompt prefix if present.\n",
        "    if text.startswith(prompt):\n",
        "        text = text[len(prompt):].strip()\n",
        "    return text.strip()\n",
        "\n",
        "def log_step(step_name: str, prompt: str, output: str, meta: dict = None):\n",
        "    record = {\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"step\": step_name,\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"model\": \"microsoft/phi-3.5-mini-instruct\",\n",
        "        \"gen_config\": gen_config,\n",
        "        \"meta\": meta or {},\n",
        "        \"prompt\": prompt,\n",
        "        \"output\": output\n",
        "    }\n",
        "    with open(PROMPT_LOG_PATH, \"a\") as f:\n",
        "        f.write(json.dumps(record, default=str) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "e1hJMHM4accR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Focused Evidence \"Slice\" for the agent (Dataset A)"
      ],
      "metadata": {
        "id": "86mB1Nj9arbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Provide the agent with only what is needed to keep the prompt small\n",
        "def build_evidence_slice_for_datasetA(evidence_pack):\n",
        "    \"\"\"\n",
        "    Keep it small + focused. This is the agent's 'input context'.\n",
        "    \"\"\"\n",
        "    keep_keys = [\n",
        "        \"emotion_by_month_date\",\n",
        "        \"net_by_month\",\n",
        "        \"topic_share_by_month\",\n",
        "        \"emotion_by_topic\",\n",
        "        \"emotion_balance_by_topic\",\n",
        "        \"topic_sizes\",\n",
        "        \"topic_keywords\",\n",
        "        \"domain_by_topic\",\n",
        "        \"emotion_by_topic_month_date\",\n",
        "        \"fear_examples\",\n",
        "        \"optimism_examples\",\n",
        "        \"topic_summary_table\"\n",
        "    ]\n",
        "    return {k: evidence_pack[k] for k in keep_keys if k in evidence_pack}\n"
      ],
      "metadata": {
        "id": "9TLVQFp5arzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Templates for Each Stage\n",
        "\n",
        "\n",
        "*   Force JSON outputs only\n",
        "*   Force Evidence References\n",
        "*   Ban hallucinated numbers - only cite values in the evidence\n",
        "\n"
      ],
      "metadata": {
        "id": "J3SpQ98pa-eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_observe(evidence_slice):\n",
        "    return f\"\"\"\n",
        "You are an analysis agent. You must ONLY use the evidence provided below (Dataset A media headlines).\n",
        "Do NOT invent numbers or facts. If something is not in evidence, say \"not available\".\n",
        "\n",
        "TASK: Produce JSON with:\n",
        "- \"observations\": 8-12 bullet observations grounded in evidence. Each observation should cite which evidence keys support it.\n",
        "- \"key_tables_used\": list of evidence keys you used.\n",
        "\n",
        "Return VALID JSON ONLY. No markdown. No extra text.\n",
        "\n",
        "EVIDENCE (Dataset A slice):\n",
        "{safe_json_dumps(evidence_slice)}\n",
        "\"\"\".strip()\n",
        "\n",
        "def prompt_hypothesize(observations_json):\n",
        "    return f\"\"\"\n",
        "You are an analysis agent. Based ONLY on the observations below, propose hypotheses that explain:\n",
        "1) how emotional framing evolves over time\n",
        "2) whether changes are driven more by topic shifts vs tone shifts within topics\n",
        "\n",
        "TASK: Return JSON with:\n",
        "- \"hypotheses\": 4-6 hypotheses. Each must be testable using the evidence keys.\n",
        "- \"tests\": for each hypothesis, list which evidence keys would validate/refute it.\n",
        "\n",
        "Return VALID JSON ONLY. No markdown. No extra text.\n",
        "\n",
        "OBSERVATIONS JSON:\n",
        "{safe_json_dumps(observations_json, max_chars=12000)}\n",
        "\"\"\".strip()\n",
        "\n",
        "def prompt_validate(evidence_slice, hypotheses_json):\n",
        "    return f\"\"\"\n",
        "You are an analysis agent. Validate each hypothesis using ONLY the evidence below.\n",
        "You must:\n",
        "- Mark each hypothesis as \"supported\", \"partially_supported\", or \"not_supported\".\n",
        "- Provide 2-4 short evidence bullets per hypothesis that reference evidence keys and (when available) specific months/topics.\n",
        "- If evidence is insufficient, say exactly what is missing.\n",
        "\n",
        "TASK: Return JSON with:\n",
        "- \"validation\": list of objects:\n",
        "  - \"hypothesis\"\n",
        "  - \"status\"\n",
        "  - \"evidence\": [ ... ]\n",
        "  - \"notes\"\n",
        "\n",
        "Return VALID JSON ONLY. No markdown. No extra text.\n",
        "\n",
        "EVIDENCE (Dataset A slice):\n",
        "{safe_json_dumps(evidence_slice)}\n",
        "\n",
        "HYPOTHESES JSON:\n",
        "{safe_json_dumps(hypotheses_json, max_chars=12000)}\n",
        "\"\"\".strip()\n",
        "\n",
        "def prompt_synthesize(observations_json, validation_json):\n",
        "    return f\"\"\"\n",
        "You are an analysis agent. Synthesize final insights for slides.\n",
        "Must be grounded in validated evidence.\n",
        "\n",
        "TASK: Return JSON with:\n",
        "- \"final_insights\": 3-6 presentation slide-ready insights, each:\n",
        "  - one sentence claim\n",
        "  - one sentence evidence grounding (cite evidence keys)\n",
        "- \"limitations\": 3-5 limitations specific to this analysis design (lexicon scoring on headlines, topic imbalance, etc.)\n",
        "- \"next_steps_datasetC\": 3-5 bullets on how to extend the same workflow to Dataset C (without doing it yet)\n",
        "\n",
        "Return VALID JSON ONLY. No markdown. No extra text.\n",
        "\n",
        "OBSERVATIONS JSON:\n",
        "{safe_json_dumps(observations_json, max_chars=12000)}\n",
        "\n",
        "VALIDATION JSON:\n",
        "{safe_json_dumps(validation_json, max_chars=12000)}\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "2M3ohZw8bCrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a JSON Parser"
      ],
      "metadata": {
        "id": "fdaaFQ0DbgtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_json(text: str):\n",
        "    \"\"\"\n",
        "    Attempts to extract the first JSON object from model output.\n",
        "    \"\"\"\n",
        "    text = text.strip()\n",
        "    # If it's already clean JSON\n",
        "    if text.startswith(\"{\") and text.endswith(\"}\"):\n",
        "        return json.loads(text)\n",
        "\n",
        "    # Try to find a JSON object substring\n",
        "    match = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
        "    if match:\n",
        "        return json.loads(match.group(0))\n",
        "\n",
        "    raise ValueError(\"Could not extract JSON from model output.\")\n"
      ],
      "metadata": {
        "id": "KR0fIQFfbg_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Agent Pipeline"
      ],
      "metadata": {
        "id": "q7Drm671brhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent_pipeline_datasetA(evidence_pack):\n",
        "    evidence_slice = build_evidence_slice_for_datasetA(evidence_pack)\n",
        "\n",
        "    # Step 1: Observe\n",
        "    print(\"STEP 1: OBSERVE\")\n",
        "    p1 = prompt_observe(evidence_slice)\n",
        "    o1 = phi_generate(p1, gen_config)\n",
        "    log_step(\"observe\", p1, o1, meta={\"dataset\": \"A\"})\n",
        "    obs = extract_json(o1)\n",
        "    print(\"✓ OBSERVE DONE\\n\")\n",
        "\n",
        "    # Step 2: Hypothesize\n",
        "    print(\"STEP 2: HYPOTHESIZE\")\n",
        "    p2 = prompt_hypothesize(obs)\n",
        "    o2 = phi_generate(p2, gen_config)\n",
        "    log_step(\"hypothesize\", p2, o2, meta={\"dataset\": \"A\"})\n",
        "    hyp = extract_json(o2)\n",
        "    print(\"✓ HYPOTHESIZE DONE\\n\")\n",
        "\n",
        "    # Step 3: Validate\n",
        "    print(\"STEP 3: VALIDATE\")\n",
        "    p3 = prompt_validate(evidence_slice, hyp)\n",
        "    o3 = phi_generate(p3, gen_config)\n",
        "    log_step(\"validate\", p3, o3, meta={\"dataset\": \"A\"})\n",
        "    val = extract_json(o3)\n",
        "    print(\"✓ VALIDATE DONE\\n\")\n",
        "\n",
        "\n",
        "    # Step 4: Synthesize\n",
        "    print(\"STEP 4: SYNTHESIZE\")\n",
        "    p4 = prompt_synthesize(obs, val)\n",
        "    o4 = phi_generate(p4, gen_config)\n",
        "    log_step(\"synthesize\", p4, o4, meta={\"dataset\": \"A\"})\n",
        "    syn = extract_json(o4)\n",
        "    print(\"✓ SYNTHESIZE DONE\\n\")\n",
        "\n",
        "\n",
        "    final = {\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"dataset\": \"A\",\n",
        "        \"observations\": obs,\n",
        "        \"hypotheses\": hyp,\n",
        "        \"validation\": val,\n",
        "        \"synthesis\": syn,\n",
        "        \"prompt_log_path\": PROMPT_LOG_PATH\n",
        "    }\n",
        "\n",
        "    with open(AGENT_OUTPUT_PATH, \"w\") as f:\n",
        "        json.dump(final, f, indent=2, default=str)\n",
        "\n",
        "    return final\n",
        "\n"
      ],
      "metadata": {
        "id": "1svDViBhbr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cSoCqGSJb36n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_results_A = run_agent_pipeline_datasetA(evidence_pack)\n",
        "agent_results_A.keys()\n"
      ],
      "metadata": {
        "id": "tqv9DX3ib4Nt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}